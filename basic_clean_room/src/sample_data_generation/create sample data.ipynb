{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2214ad07-92b1-4bda-b34f-f31fc758459e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Healthcare Sample Data Generator\n",
    "\n",
    "This notebook generates synthetic healthcare data for clean room demonstrations and testing. It creates a star schema with one fact table and four dimension tables, ensuring complete referential integrity before persisting to Unity Catalog.\n",
    "\n",
    "## Data Model\n",
    "\n",
    "**Fact Table:**\n",
    "* `visits` - Patient visit records linking to all dimension tables\n",
    "\n",
    "**Dimension Tables:**\n",
    "* `patients` - Patient demographic information\n",
    "* `doctors` - Healthcare provider information with specialties\n",
    "* `hospitals` - Hospital location data\n",
    "* `diagnoses` - Medical diagnosis codes (ICD-10 format)\n",
    "\n",
    "## Notebook Flow\n",
    "\n",
    "1. **Configure Catalog and Schema** - Widget inputs for target catalog and schema (default: `mkgs.clean_room_sample_data`)\n",
    "2. **Set Default Namespace** - Execute `USE CATALOG` and `USE SCHEMA` statements\n",
    "3. **Create Schema** - Ensure the target schema exists\n",
    "4. **Generate Sample Data** - Programmatically create randomized healthcare data:\n",
    "\t* Patients: 900-1100 (random)\n",
    "\t* Visits: 1400-1600 (random)\n",
    "\t* Doctors: 15-30 (random)\n",
    "\t* Hospitals: 3 (fixed)\n",
    "\t* Diagnoses: 15 (all available)\n",
    "5. **Verify Referential Integrity** - Run comprehensive checks:\n",
    "\t* Primary key uniqueness\n",
    "\t* Null value detection\n",
    "\t* Foreign key validation\n",
    "\t* **Only save tables if all checks pass**\n",
    "\n",
    "## Key Features\n",
    "\n",
    "* **Randomized data generation** - Different counts on each run (with seed for reproducibility)\n",
    "* **Referential integrity enforcement** - Tables only saved if validation succeeds\n",
    "* **Overwrite mode** - Tables are created or replaced without manual drops\n",
    "* **ICD-10 diagnosis codes** - Realistic medical coding standards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4aa06b64-ad88-4513-af9e-7ae006f0f289",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Configure Catalog and Schema"
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"catalog\", \"cr_owner_catalog\", \"Catalog\")\n",
    "dbutils.widgets.text(\"schema\", \"patient_visits\", \"Schema\")\n",
    "\n",
    "catalog = dbutils.widgets.get(\"catalog\")\n",
    "schema = dbutils.widgets.get(\"schema\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f0afc05-529a-4854-9b49-28379dbbb309",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE SCHEMA IF NOT EXISTS IDENTIFIER(:catalog || \".\" || :schema);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f470e77c-bfae-4926-9d83-6676413058ae",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Set Default Catalog and Schema"
    }
   },
   "outputs": [],
   "source": [
    "# Use the specified catalog and schema as defaults\n",
    "spark.sql(f\"USE CATALOG {catalog}\")\n",
    "spark.sql(f\"USE SCHEMA {schema}\")\n",
    "\n",
    "print(f\"Using catalog: {catalog}, schema: {schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "676ee74b-c41a-4667-bd04-093586a6eb6e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 4"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Generate random counts for each entity type\n",
    "num_patients = random.randint(900, 1100)\n",
    "num_visits = random.randint(1400, 1600)\n",
    "num_doctors = random.randint(15, 30)\n",
    "num_hospitals = 3\n",
    "num_diagnoses = 15  # Use all 15 diagnoses\n",
    "\n",
    "print(f\"Generating data with:\")\n",
    "print(f\"  Patients: {num_patients}\")\n",
    "print(f\"  Visits: {num_visits}\")\n",
    "print(f\"  Doctors: {num_doctors}\")\n",
    "print(f\"  Hospitals: {num_hospitals}\")\n",
    "print(f\"  Diagnoses: {num_diagnoses}\")\n",
    "print()\n",
    "\n",
    "# Dimension table: hospitals (fixed at 3)\n",
    "hospitals = [\n",
    "\tRow(hospital_id=301, name=\"General Hospital\", city=\"Springfield\")\n",
    "\t, Row(hospital_id=302, name=\"City Medical Center\", city=\"Rivertown\")\n",
    "\t, Row(hospital_id=303, name=\"Children's Hospital\", city=\"Lakeside\")\n",
    "]\n",
    "df_hospitals = spark.createDataFrame(hospitals)\n",
    "\n",
    "# Dimension table: doctors (random between 15-30)\n",
    "specialties = [\n",
    "\t\"Cardiology\", \"Neurology\", \"Pediatrics\", \"Orthopedics\", \"Dermatology\"\n",
    "\t, \"Oncology\", \"Psychiatry\", \"Endocrinology\", \"Gastroenterology\", \"Pulmonology\"\n",
    "\t, \"Rheumatology\", \"Urology\", \"Nephrology\", \"Ophthalmology\", \"Otolaryngology\"\n",
    "\t, \"Radiology\", \"Anesthesiology\", \"Emergency Medicine\", \"Family Medicine\", \"Internal Medicine\"\n",
    "\t, \"Obstetrics\", \"Gynecology\", \"Pathology\", \"Surgery\", \"Hematology\"\n",
    "\t, \"Infectious Disease\", \"Allergy\", \"Sports Medicine\", \"Geriatrics\", \"Palliative Care\"\n",
    "]\n",
    "doctor_names = [\n",
    "\t\"Dr. Adams\", \"Dr. Baker\", \"Dr. Clark\", \"Dr. Davis\", \"Dr. Evans\"\n",
    "\t, \"Dr. Foster\", \"Dr. Green\", \"Dr. Harris\", \"Dr. Irwin\", \"Dr. Johnson\"\n",
    "\t, \"Dr. Kelly\", \"Dr. Lopez\", \"Dr. Murphy\", \"Dr. Nelson\", \"Dr. Owens\"\n",
    "\t, \"Dr. Parker\", \"Dr. Quinn\", \"Dr. Reed\", \"Dr. Stone\", \"Dr. Turner\"\n",
    "\t, \"Dr. Allen\", \"Dr. Bell\", \"Dr. Cooper\", \"Dr. Dixon\", \"Dr. Ellis\"\n",
    "\t, \"Dr. Fisher\", \"Dr. Gray\", \"Dr. Hughes\", \"Dr. Ingram\", \"Dr. Jenkins\"\n",
    "]\n",
    "\n",
    "doctors = []\n",
    "for i in range(num_doctors):\n",
    "\tdoctor_id = 201 + i\n",
    "\tname = doctor_names[i % len(doctor_names)]\n",
    "\tspecialty = specialties[i % len(specialties)]\n",
    "\tdoctors.append(Row(doctor_id=doctor_id, name=name, specialty=specialty))\n",
    "\n",
    "df_doctors = spark.createDataFrame(doctors)\n",
    "\n",
    "# Dimension table: diagnoses (all 15)\n",
    "all_diagnoses = [\n",
    "\tRow(diagnosis_id=401, code=\"I10\", description=\"Hypertension\")\n",
    "\t, Row(diagnosis_id=402, code=\"E11\", description=\"Type 2 Diabetes\")\n",
    "\t, Row(diagnosis_id=403, code=\"J45\", description=\"Asthma\")\n",
    "\t, Row(diagnosis_id=404, code=\"F32\", description=\"Depression\")\n",
    "\t, Row(diagnosis_id=405, code=\"M79\", description=\"Fibromyalgia\")\n",
    "\t, Row(diagnosis_id=406, code=\"K21\", description=\"GERD\")\n",
    "\t, Row(diagnosis_id=407, code=\"I25\", description=\"Coronary Artery Disease\")\n",
    "\t, Row(diagnosis_id=408, code=\"J44\", description=\"COPD\")\n",
    "\t, Row(diagnosis_id=409, code=\"N18\", description=\"Chronic Kidney Disease\")\n",
    "\t, Row(diagnosis_id=410, code=\"E78\", description=\"Hyperlipidemia\")\n",
    "\t, Row(diagnosis_id=411, code=\"M81\", description=\"Osteoporosis\")\n",
    "\t, Row(diagnosis_id=412, code=\"G43\", description=\"Migraine\")\n",
    "\t, Row(diagnosis_id=413, code=\"K58\", description=\"Irritable Bowel Syndrome\")\n",
    "\t, Row(diagnosis_id=414, code=\"L40\", description=\"Psoriasis\")\n",
    "\t, Row(diagnosis_id=415, code=\"F41\", description=\"Anxiety Disorder\")\n",
    "]\n",
    "\n",
    "# Use all 15 diagnoses\n",
    "diagnoses = all_diagnoses[:num_diagnoses]\n",
    "df_diagnoses = spark.createDataFrame(diagnoses)\n",
    "\n",
    "# Generate patients programmatically (random between 900-1100)\n",
    "first_names = [\"Alice\", \"Bob\", \"Carol\", \"David\", \"Emma\", \"Frank\", \"Grace\", \"Henry\", \"Iris\", \"Jack\"\n",
    "\t, \"Karen\", \"Leo\", \"Maria\", \"Nathan\", \"Olivia\", \"Paul\", \"Quinn\", \"Ryan\", \"Sarah\", \"Tom\"\n",
    "\t, \"Uma\", \"Victor\", \"Wendy\", \"Xavier\", \"Yara\", \"Zack\", \"Amy\", \"Brian\", \"Chloe\", \"Daniel\"\n",
    "\t, \"Emily\", \"Felix\", \"Gina\", \"Hugo\", \"Ivy\", \"James\", \"Kate\", \"Liam\", \"Mia\", \"Noah\"\n",
    "\t, \"Ava\", \"Ben\", \"Cara\", \"Dean\", \"Ella\", \"Finn\", \"Gia\", \"Hank\", \"Isla\", \"Jake\"]\n",
    "last_names = [\"Smith\", \"Jones\", \"Lee\", \"Kim\", \"Wilson\", \"Miller\", \"Taylor\", \"Brown\", \"Chen\", \"Davis\"\n",
    "\t, \"White\", \"Martinez\", \"Garcia\", \"Rodriguez\", \"Anderson\", \"Thomas\", \"Jackson\", \"Moore\", \"Martin\", \"Thompson\"\n",
    "\t, \"Patel\", \"Harris\", \"Clark\", \"Lewis\", \"Walker\", \"Hall\", \"Young\", \"King\", \"Wright\", \"Scott\"\n",
    "\t, \"Green\", \"Baker\", \"Adams\", \"Nelson\", \"Carter\", \"Mitchell\", \"Perez\", \"Roberts\", \"Turner\", \"Phillips\"]\n",
    "genders = [\"M\", \"F\"]\n",
    "\n",
    "patients = []\n",
    "for i in range(num_patients):\n",
    "\tpatient_id = 101 + i\n",
    "\tfirst_name = first_names[i % len(first_names)]\n",
    "\tlast_name = last_names[(i // len(first_names)) % len(last_names)]\n",
    "\tname = f\"{first_name} {last_name}\"\n",
    "\t# Generate random DOB between 1950 and 2010\n",
    "\tyear = 1950 + (i % 61)\n",
    "\tmonth = 1 + (i % 12)\n",
    "\tday = 1 + (i % 28)\n",
    "\tdob = f\"{year:04d}-{month:02d}-{day:02d}\"\n",
    "\tgender = genders[i % 2]\n",
    "\tpatients.append(Row(patient_id=patient_id, name=name, dob=dob, gender=gender))\n",
    "\n",
    "df_patients = spark.createDataFrame(patients)\n",
    "\n",
    "# Generate visits programmatically with valid foreign keys (random between 1400-1600)\n",
    "patient_ids = list(range(101, 101 + num_patients))\n",
    "doctor_ids = list(range(201, 201 + num_doctors))\n",
    "hospital_ids = [301, 302, 303]\n",
    "diagnosis_ids = [d.diagnosis_id for d in diagnoses]\n",
    "\n",
    "patient_visits = []\n",
    "start_date = datetime(2025, 1, 1)\n",
    "for i in range(num_visits):\n",
    "\tvisit_id = i + 1\n",
    "\tpatient_id = random.choice(patient_ids)\n",
    "\tdoctor_id = random.choice(doctor_ids)\n",
    "\thospital_id = random.choice(hospital_ids)\n",
    "\tdiagnosis_id = random.choice(diagnosis_ids)\n",
    "\t# Spread visits across 365 days\n",
    "\tvisit_date = (start_date + timedelta(days=i % 365)).strftime(\"%Y-%m-%d\")\n",
    "\tpatient_visits.append(Row(\n",
    "\t\tvisit_id=visit_id\n",
    "\t\t, patient_id=patient_id\n",
    "\t\t, doctor_id=doctor_id\n",
    "\t\t, hospital_id=hospital_id\n",
    "\t\t, diagnosis_id=diagnosis_id\n",
    "\t\t, visit_date=visit_date\n",
    "\t))\n",
    "\n",
    "df_patient_visits = spark.createDataFrame(patient_visits)\n",
    "\n",
    "print(f\"\\nGenerated:\")\n",
    "print(f\"  {df_patients.count()} patients\")\n",
    "print(f\"  {df_patient_visits.count()} visits\")\n",
    "print(f\"  {df_doctors.count()} doctors\")\n",
    "print(f\"  {df_hospitals.count()} hospitals\")\n",
    "print(f\"  {df_diagnoses.count()} diagnoses\")\n",
    "\n",
    "display(df_patient_visits.limit(10))\n",
    "display(df_patients.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b4c57bc-13d5-4f56-b932-6a1642ea3910",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Verify Referential Integrity"
    }
   },
   "outputs": [],
   "source": [
    "print(\"=== REFERENTIAL INTEGRITY CHECKS ===\\n\")\n",
    "\n",
    "# Check 1: Verify primary key uniqueness in dimension tables\n",
    "print(\"1. PRIMARY KEY UNIQUENESS:\")\n",
    "print(f\"   Patients: {df_patients.count()} total, {df_patients.select('patient_id').distinct().count()} unique patient_ids\")\n",
    "print(f\"   Doctors: {df_doctors.count()} total, {df_doctors.select('doctor_id').distinct().count()} unique doctor_ids\")\n",
    "print(f\"   Hospitals: {df_hospitals.count()} total, {df_hospitals.select('hospital_id').distinct().count()} unique hospital_ids\")\n",
    "print(f\"   Diagnoses: {df_diagnoses.count()} total, {df_diagnoses.select('diagnosis_id').distinct().count()} unique diagnosis_ids\")\n",
    "print(f\"   Visits: {df_patient_visits.count()} total, {df_patient_visits.select('visit_id').distinct().count()} unique visit_ids\")\n",
    "\n",
    "# Check 2: Verify no nulls in key columns\n",
    "print(\"\\n2. NULL CHECKS IN KEY COLUMNS:\")\n",
    "print(f\"   Null patient_ids in visits: {df_patient_visits.filter('patient_id IS NULL').count()}\")\n",
    "print(f\"   Null doctor_ids in visits: {df_patient_visits.filter('doctor_id IS NULL').count()}\")\n",
    "print(f\"   Null hospital_ids in visits: {df_patient_visits.filter('hospital_id IS NULL').count()}\")\n",
    "print(f\"   Null diagnosis_ids in visits: {df_patient_visits.filter('diagnosis_id IS NULL').count()}\")\n",
    "\n",
    "# Check 3: Verify foreign key references (patient_id)\n",
    "print(\"\\n3. FOREIGN KEY INTEGRITY:\")\n",
    "patient_ids_in_visits = df_patient_visits.select('patient_id').distinct()\n",
    "patient_ids_in_dim = df_patients.select('patient_id')\n",
    "invalid_patients = patient_ids_in_visits.join(patient_ids_in_dim, 'patient_id', 'left_anti')\n",
    "print(f\"   Invalid patient_ids in visits: {invalid_patients.count()}\")\n",
    "if invalid_patients.count() > 0:\n",
    "\tprint(f\"   Invalid patient_ids: {[row.patient_id for row in invalid_patients.collect()]}\")\n",
    "\n",
    "# Check 4: Verify foreign key references (doctor_id)\n",
    "doctor_ids_in_visits = df_patient_visits.select('doctor_id').distinct()\n",
    "doctor_ids_in_dim = df_doctors.select('doctor_id')\n",
    "invalid_doctors = doctor_ids_in_visits.join(doctor_ids_in_dim, 'doctor_id', 'left_anti')\n",
    "print(f\"   Invalid doctor_ids in visits: {invalid_doctors.count()}\")\n",
    "if invalid_doctors.count() > 0:\n",
    "\tprint(f\"   Invalid doctor_ids: {[row.doctor_id for row in invalid_doctors.collect()]}\")\n",
    "\n",
    "# Check 5: Verify foreign key references (hospital_id)\n",
    "hospital_ids_in_visits = df_patient_visits.select('hospital_id').distinct()\n",
    "hospital_ids_in_dim = df_hospitals.select('hospital_id')\n",
    "invalid_hospitals = hospital_ids_in_visits.join(hospital_ids_in_dim, 'hospital_id', 'left_anti')\n",
    "print(f\"   Invalid hospital_ids in visits: {invalid_hospitals.count()}\")\n",
    "if invalid_hospitals.count() > 0:\n",
    "\tprint(f\"   Invalid hospital_ids: {[row.hospital_id for row in invalid_hospitals.collect()]}\")\n",
    "\n",
    "# Check 6: Verify foreign key references (diagnosis_id)\n",
    "diagnosis_ids_in_visits = df_patient_visits.select('diagnosis_id').distinct()\n",
    "diagnosis_ids_in_dim = df_diagnoses.select('diagnosis_id')\n",
    "invalid_diagnoses = diagnosis_ids_in_visits.join(diagnosis_ids_in_dim, 'diagnosis_id', 'left_anti')\n",
    "print(f\"   Invalid diagnosis_ids in visits: {invalid_diagnoses.count()}\")\n",
    "if invalid_diagnoses.count() > 0:\n",
    "\tprint(f\"   Invalid diagnosis_ids: {[row.diagnosis_id for row in invalid_diagnoses.collect()]}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n=== SUMMARY ===\")\n",
    "total_issues = (\n",
    "\t(df_patients.count() - df_patients.select('patient_id').distinct().count()) +\n",
    "\t(df_doctors.count() - df_doctors.select('doctor_id').distinct().count()) +\n",
    "\t(df_hospitals.count() - df_hospitals.select('hospital_id').distinct().count()) +\n",
    "\t(df_diagnoses.count() - df_diagnoses.select('diagnosis_id').distinct().count()) +\n",
    "\t(df_patient_visits.count() - df_patient_visits.select('visit_id').distinct().count()) +\n",
    "\tdf_patient_visits.filter('patient_id IS NULL').count() +\n",
    "\tdf_patient_visits.filter('doctor_id IS NULL').count() +\n",
    "\tdf_patient_visits.filter('hospital_id IS NULL').count() +\n",
    "\tdf_patient_visits.filter('diagnosis_id IS NULL').count() +\n",
    "\tinvalid_patients.count() +\n",
    "\tinvalid_doctors.count() +\n",
    "\tinvalid_hospitals.count() +\n",
    "\tinvalid_diagnoses.count()\n",
    ")\n",
    "\n",
    "if total_issues == 0:\n",
    "\tprint(\"✓ All referential integrity checks PASSED\")\n",
    "\tprint(\"✓ No duplicate primary keys\")\n",
    "\tprint(\"✓ No null foreign keys\")\n",
    "\tprint(\"✓ All foreign keys reference valid dimension records\")\n",
    "\t\n",
    "\t# Only save tables if integrity checks pass\n",
    "\tprint(\"\\n=== SAVING TABLES ===\")\n",
    "\tdf_patient_visits.write.mode(\"overwrite\").saveAsTable(\"visits\")\n",
    "\tprint(\"✓ Saved table: visits\")\n",
    "\t\n",
    "\tdf_patients.write.mode(\"overwrite\").saveAsTable(\"patients\")\n",
    "\tprint(\"✓ Saved table: patients\")\n",
    "\t\n",
    "\tdf_doctors.write.mode(\"overwrite\").saveAsTable(\"doctors\")\n",
    "\tprint(\"✓ Saved table: doctors\")\n",
    "\t\n",
    "\tdf_hospitals.write.mode(\"overwrite\").saveAsTable(\"hospitals\")\n",
    "\tprint(\"✓ Saved table: hospitals\")\n",
    "\t\n",
    "\tdf_diagnoses.write.mode(\"overwrite\").saveAsTable(\"diagnoses\")\n",
    "\tprint(\"✓ Saved table: diagnoses\")\n",
    "\t\n",
    "\tprint(\"\\n✓ All tables created/replaced successfully in schema\")\n",
    "else:\n",
    "\tprint(f\"✗ Found {total_issues} integrity issue(s)\")\n",
    "\tprint(\"✗ TABLES NOT SAVED - Fix integrity issues before saving\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6633261163319651,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "create sample data",
   "widgets": {
    "catalog": {
     "currentValue": "mkgs",
     "nuid": "40392471-a79a-48dd-aa84-a9e6665bbe83",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "cr_owner_catalog",
      "label": "Catalog",
      "name": "catalog",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "cr_owner_catalog",
      "label": "Catalog",
      "name": "catalog",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "schema": {
     "currentValue": "clean_room_sample_data",
     "nuid": "dd24bcb8-71c2-4dd7-8dee-5a43b6779cd8",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "patient_visits",
      "label": "Schema",
      "name": "schema",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "patient_visits",
      "label": "Schema",
      "name": "schema",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
